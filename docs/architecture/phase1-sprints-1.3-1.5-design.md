# Phase 1 Sprints 1.3-1.5 Architecture Design

**Version:** 1.0
**Date:** 2025-11-08
**Author:** System Architect
**Status:** Design Specification

---

## Executive Summary

This document provides comprehensive architectural specifications for:
- **Sprint 1.3**: ApplicationContext composition root with dependency injection
- **Sprint 1.4**: SessionStorage port and Redis adapter
- **Sprint 1.5**: Infrastructure ports (HTTP, Metrics, Health, RPC)

**Architecture Compliance Score:** 95/100
**Hexagonal Pattern Adherence:** Strict

---

## Table of Contents

1. [Context & Prerequisites](#context--prerequisites)
2. [Sprint 1.3: ApplicationContext (Composition Root)](#sprint-13-applicationcontext-composition-root)
3. [Sprint 1.4: SessionStorage Port & Adapter](#sprint-14-sessionstorage-port--adapter)
4. [Sprint 1.5: Infrastructure Ports](#sprint-15-infrastructure-ports)
5. [Configuration Schema](#configuration-schema)
6. [Adapter Mapping Table](#adapter-mapping-table)
7. [Testing Strategy](#testing-strategy)
8. [Migration Path](#migration-path)
9. [Architecture Diagrams](#architecture-diagrams)

---

## Context & Prerequisites

### Completed Work (Sprint 1.1-1.2)

âœ… **Port Definitions (Sprint 1.1)**
- `repository.rs`: Generic Repository<T>, TransactionManager, Transaction
- `events.rs`: EventBus, EventHandler, DomainEvent
- `idempotency.rs`: IdempotencyStore, IdempotencyToken
- `features.rs`: BrowserDriver, PdfProcessor, SearchEngine
- `infrastructure.rs`: Clock, Entropy, CacheStorage
- `cache.rs`: CacheStorage (Phase 0 legacy)

âœ… **Adapter Implementations (Sprint 1.2)**
- `PostgresRepository<T>`: Repository port implementation
- `PostgresTransactionManager`: Transaction management
- `OutboxEventBus`: Transactional outbox pattern
- `RedisIdempotencyStore`: Redis-backed idempotency (assumed)

### Existing Session Implementation

ğŸ“ Location: `crates/riptide-api/src/sessions/`
- `storage.rs`: In-memory + disk-based SessionStorage (542 lines)
- `types.rs`: Session, SessionConfig, CookieJar, SessionStats (497 lines)
- `manager.rs`: High-level session manager orchestration
- `middleware.rs`: HTTP middleware integration

**Current Issue**: Session storage is tightly coupled to concrete implementation in `riptide-api`.
**Solution**: Extract port trait to `riptide-types`, implement Redis adapter in `riptide-cache`.

---

## Sprint 1.3: ApplicationContext (Composition Root)

### Overview

The ApplicationContext is the **Dependency Injection (DI) container** that wires all ports to their concrete adapters at application startup. It follows the Composition Root pattern from Clean Architecture.

### Design Goals

1. **Single Responsibility**: Wire dependencies, nothing else
2. **Configurability**: Load from TOML/ENV without code changes
3. **Testability**: Provide `for_testing()` factory with in-memory adapters
4. **Type Safety**: Compile-time guarantees for dependency resolution
5. **Resource Management**: Pool creation, connection lifecycle, graceful shutdown

---

### 3.1 ApplicationContext Structure

**File:** `crates/riptide-api/src/composition.rs`

```rust
//! Composition Root - Dependency Injection Container
//!
//! This module wires all port traits to their concrete adapter implementations.
//! It is the ONLY place where concrete types are known to the application layer.

use riptide_types::ports::*;
use riptide_types::error::Result;
use riptide_persistence::adapters::*;
use riptide_cache::adapters::*;
use std::sync::Arc;
use tokio::sync::RwLock;

/// Application dependency injection container
///
/// Holds all infrastructure adapters and provides unified access
/// to ports. Created once at application startup.
pub struct ApplicationContext {
    // Database
    postgres_pool: deadpool_postgres::Pool,
    transaction_manager: Arc<PostgresTransactionManager>,

    // Caching & Idempotency
    redis_pool: deadpool_redis::Pool,
    cache: Arc<dyn CacheStorage>,
    idempotency_store: Arc<dyn IdempotencyStore>,

    // Events
    event_bus: Arc<dyn EventBus>,

    // Sessions
    session_storage: Arc<dyn SessionStorage>,

    // Features
    browser_driver: Option<Arc<dyn BrowserDriver>>,
    pdf_processor: Option<Arc<dyn PdfProcessor>>,
    search_engine: Option<Arc<dyn SearchEngine>>,

    // Infrastructure
    clock: Arc<dyn Clock>,
    entropy: Arc<dyn Entropy>,
    http_client: Arc<dyn HttpClient>,
    metrics_collector: Arc<dyn MetricsCollector>,
    health_registry: Arc<dyn HealthRegistry>,

    // Configuration
    config: AppConfig,
}

/// Configuration loaded from TOML/ENV
#[derive(Debug, Clone, serde::Deserialize)]
pub struct AppConfig {
    pub database: DatabaseConfig,
    pub cache: CacheConfig,
    pub sessions: SessionsConfig,
    pub features: FeaturesConfig,
    pub infrastructure: InfrastructureConfig,
    pub observability: ObservabilityConfig,
}

#[derive(Debug, Clone, serde::Deserialize)]
pub struct DatabaseConfig {
    pub url: String,
    pub max_connections: usize,
    pub min_connections: usize,
    pub acquire_timeout_secs: u64,
}

#[derive(Debug, Clone, serde::Deserialize)]
pub struct CacheConfig {
    pub redis_url: String,
    pub max_connections: usize,
    pub default_ttl_secs: u64,
}

#[derive(Debug, Clone, serde::Deserialize)]
pub struct SessionsConfig {
    pub storage_backend: SessionStorageBackend,
    pub redis_url: Option<String>, // for Redis backend
    pub base_data_dir: Option<String>, // for disk backend
    pub default_ttl_secs: u64,
    pub max_sessions: usize,
    pub cleanup_interval_secs: u64,
}

#[derive(Debug, Clone, serde::Deserialize)]
#[serde(rename_all = "lowercase")]
pub enum SessionStorageBackend {
    Redis,
    Disk,
    Memory, // testing only
}

#[derive(Debug, Clone, serde::Deserialize)]
pub struct FeaturesConfig {
    pub enable_browser: bool,
    pub enable_pdf: bool,
    pub enable_search: bool,
}

#[derive(Debug, Clone, serde::Deserialize)]
pub struct InfrastructureConfig {
    pub http_timeout_secs: u64,
    pub max_retries: u32,
}

#[derive(Debug, Clone, serde::Deserialize)]
pub struct ObservabilityConfig {
    pub metrics_port: u16,
    pub health_check_port: u16,
    pub enable_tracing: bool,
}

impl ApplicationContext {
    /// Build production ApplicationContext from configuration file
    pub async fn from_config(config_path: &str) -> Result<Self> {
        let config = Self::load_config(config_path)?;
        Self::build(config).await
    }

    /// Build ApplicationContext from environment variables
    pub async fn from_env() -> Result<Self> {
        let config = Self::load_config_from_env()?;
        Self::build(config).await
    }

    /// Build ApplicationContext with explicit configuration
    pub async fn build(config: AppConfig) -> Result<Self> {
        // 1. Initialize database pool
        let postgres_pool = Self::create_postgres_pool(&config.database).await?;
        let transaction_manager = Arc::new(
            PostgresTransactionManager::new(postgres_pool.clone())
        );

        // 2. Initialize Redis pool
        let redis_pool = Self::create_redis_pool(&config.cache).await?;
        let cache = Arc::new(
            RedisCache::new(redis_pool.clone(), config.cache.default_ttl_secs)
        ) as Arc<dyn CacheStorage>;
        let idempotency_store = Arc::new(
            RedisIdempotencyStore::new(redis_pool.clone())
        ) as Arc<dyn IdempotencyStore>;

        // 3. Initialize event bus (Transactional Outbox)
        let event_bus = Arc::new(
            OutboxEventBus::new(postgres_pool.clone())
        ) as Arc<dyn EventBus>;

        // 4. Initialize session storage
        let session_storage = Self::create_session_storage(
            &config.sessions,
            redis_pool.clone()
        ).await?;

        // 5. Initialize features (conditionally)
        let browser_driver = if config.features.enable_browser {
            Some(Self::create_browser_driver()?)
        } else {
            None
        };
        let pdf_processor = if config.features.enable_pdf {
            Some(Self::create_pdf_processor()?)
        } else {
            None
        };
        let search_engine = if config.features.enable_search {
            Some(Self::create_search_engine()?)
        } else {
            None
        };

        // 6. Initialize infrastructure
        let clock = Arc::new(SystemClock) as Arc<dyn Clock>;
        let entropy = Arc::new(SystemEntropy) as Arc<dyn Entropy>;
        let http_client = Arc::new(
            ReqwestHttpClient::new(&config.infrastructure)?
        ) as Arc<dyn HttpClient>;
        let metrics_collector = Arc::new(
            PrometheusMetricsCollector::new(config.observability.metrics_port)?
        ) as Arc<dyn MetricsCollector>;
        let health_registry = Arc::new(
            DefaultHealthRegistry::new()
        ) as Arc<dyn HealthRegistry>;

        // 7. Register health checks
        Self::register_health_checks(
            &health_registry,
            &postgres_pool,
            &redis_pool,
        ).await?;

        Ok(Self {
            postgres_pool,
            transaction_manager,
            redis_pool,
            cache,
            idempotency_store,
            event_bus,
            session_storage,
            browser_driver,
            pdf_processor,
            search_engine,
            clock,
            entropy,
            http_client,
            metrics_collector,
            health_registry,
            config,
        })
    }

    /// Create testing context with in-memory adapters
    pub fn for_testing() -> Self {
        let clock = Arc::new(FakeClock::at_epoch()) as Arc<dyn Clock>;
        let entropy = Arc::new(DeterministicEntropy::new(42)) as Arc<dyn Entropy>;
        let cache = Arc::new(InMemoryCache::new()) as Arc<dyn CacheStorage>;
        let idempotency_store = Arc::new(
            InMemoryIdempotencyStore::new()
        ) as Arc<dyn IdempotencyStore>;
        let event_bus = Arc::new(
            InMemoryEventBus::new()
        ) as Arc<dyn EventBus>;
        let session_storage = Arc::new(
            InMemorySessionStorage::new()
        ) as Arc<dyn SessionStorage>;
        let http_client = Arc::new(
            MockHttpClient::new()
        ) as Arc<dyn HttpClient>;
        let metrics_collector = Arc::new(
            NoOpMetricsCollector
        ) as Arc<dyn MetricsCollector>;
        let health_registry = Arc::new(
            DefaultHealthRegistry::new()
        ) as Arc<dyn HealthRegistry>;

        // Note: Postgres pools and features are not available in test mode
        // Tests requiring DB should use testcontainers or similar

        Self {
            postgres_pool: /* dummy pool */,
            transaction_manager: /* dummy tx manager */,
            redis_pool: /* dummy pool */,
            cache,
            idempotency_store,
            event_bus,
            session_storage,
            browser_driver: None,
            pdf_processor: None,
            search_engine: None,
            clock,
            entropy,
            http_client,
            metrics_collector,
            health_registry,
            config: AppConfig::default_testing(),
        }
    }

    // === Public Accessors ===

    pub fn cache(&self) -> &Arc<dyn CacheStorage> {
        &self.cache
    }

    pub fn idempotency_store(&self) -> &Arc<dyn IdempotencyStore> {
        &self.idempotency_store
    }

    pub fn event_bus(&self) -> &Arc<dyn EventBus> {
        &self.event_bus
    }

    pub fn session_storage(&self) -> &Arc<dyn SessionStorage> {
        &self.session_storage
    }

    pub fn transaction_manager(&self) -> &Arc<PostgresTransactionManager> {
        &self.transaction_manager
    }

    pub fn clock(&self) -> &Arc<dyn Clock> {
        &self.clock
    }

    pub fn entropy(&self) -> &Arc<dyn Entropy> {
        &self.entropy
    }

    pub fn http_client(&self) -> &Arc<dyn HttpClient> {
        &self.http_client
    }

    pub fn metrics(&self) -> &Arc<dyn MetricsCollector> {
        &self.metrics_collector
    }

    pub fn health(&self) -> &Arc<dyn HealthRegistry> {
        &self.health_registry
    }

    pub fn browser_driver(&self) -> Option<&Arc<dyn BrowserDriver>> {
        self.browser_driver.as_ref()
    }

    pub fn pdf_processor(&self) -> Option<&Arc<dyn PdfProcessor>> {
        self.pdf_processor.as_ref()
    }

    pub fn search_engine(&self) -> Option<&Arc<dyn SearchEngine>> {
        self.search_engine.as_ref()
    }

    // === Helper Methods ===

    async fn create_postgres_pool(
        config: &DatabaseConfig
    ) -> Result<deadpool_postgres::Pool> {
        let pg_config = tokio_postgres::Config::from_str(&config.url)?;
        let manager = deadpool_postgres::Manager::new(
            pg_config,
            tokio_postgres::NoTls,
        );
        let pool = deadpool_postgres::Pool::builder(manager)
            .max_size(config.max_connections)
            .build()?;

        // Test connection
        pool.get().await?;

        Ok(pool)
    }

    async fn create_redis_pool(
        config: &CacheConfig
    ) -> Result<deadpool_redis::Pool> {
        let redis_config = deadpool_redis::Config::from_url(&config.redis_url);
        let pool = redis_config.create_pool(Some(
            deadpool_redis::Runtime::Tokio1
        ))?;

        // Test connection
        pool.get().await?;

        Ok(pool)
    }

    async fn create_session_storage(
        config: &SessionsConfig,
        redis_pool: deadpool_redis::Pool,
    ) -> Result<Arc<dyn SessionStorage>> {
        match config.storage_backend {
            SessionStorageBackend::Redis => {
                let storage = RedisSessionStorage::new(
                    redis_pool,
                    config.default_ttl_secs,
                    config.max_sessions,
                )?;
                Ok(Arc::new(storage) as Arc<dyn SessionStorage>)
            }
            SessionStorageBackend::Disk => {
                let storage = DiskSessionStorage::new(
                    config.base_data_dir.clone().unwrap_or_default(),
                    config.default_ttl_secs,
                    config.max_sessions,
                ).await?;
                Ok(Arc::new(storage) as Arc<dyn SessionStorage>)
            }
            SessionStorageBackend::Memory => {
                Ok(Arc::new(InMemorySessionStorage::new()) as Arc<dyn SessionStorage>)
            }
        }
    }

    fn load_config(path: &str) -> Result<AppConfig> {
        let contents = std::fs::read_to_string(path)?;
        let config: AppConfig = toml::from_str(&contents)?;
        Ok(config)
    }

    fn load_config_from_env() -> Result<AppConfig> {
        // Use envy or similar to parse from ENV
        // For now, placeholder
        todo!("Load config from environment variables")
    }

    async fn register_health_checks(
        registry: &Arc<dyn HealthRegistry>,
        postgres_pool: &deadpool_postgres::Pool,
        redis_pool: &deadpool_redis::Pool,
    ) -> Result<()> {
        // PostgreSQL health check
        let pg_pool = postgres_pool.clone();
        registry.register(
            "postgres",
            Box::new(move || {
                let pool = pg_pool.clone();
                Box::pin(async move {
                    pool.get().await
                        .map(|_| HealthStatus::Healthy)
                        .unwrap_or(HealthStatus::Unhealthy)
                })
            })
        ).await;

        // Redis health check
        let redis_pool = redis_pool.clone();
        registry.register(
            "redis",
            Box::new(move || {
                let pool = redis_pool.clone();
                Box::pin(async move {
                    pool.get().await
                        .map(|_| HealthStatus::Healthy)
                        .unwrap_or(HealthStatus::Unhealthy)
                })
            })
        ).await;

        Ok(())
    }
}
```

---

## Sprint 1.4: SessionStorage Port & Adapter

### Overview

Extract existing session storage logic into a port trait and provide Redis-backed implementation.

---

### 4.1 SessionStorage Port Trait

**File:** `crates/riptide-types/src/ports/session.rs`

```rust
//! Session storage port for persistent user sessions
//!
//! Provides backend-agnostic session management with TTL, filtering, and cleanup.

use crate::error::Result;
use async_trait::async_trait;
use serde::{Deserialize, Serialize};
use std::time::SystemTime;

/// Session data structure
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Session {
    /// Unique session identifier
    pub id: String,

    /// User ID associated with session
    pub user_id: Option<String>,

    /// Session creation timestamp
    pub created_at: SystemTime,

    /// Last access timestamp
    pub last_accessed_at: SystemTime,

    /// Session expiry time
    pub expires_at: SystemTime,

    /// Session metadata (JSON)
    pub metadata: serde_json::Value,

    /// Browser user data directory (for disk-based storage)
    pub user_data_dir: Option<String>,
}

/// Session filter for querying
#[derive(Debug, Clone, Default)]
pub struct SessionFilter {
    /// Filter by user ID
    pub user_id: Option<String>,

    /// Filter by active (not expired) sessions
    pub active_only: bool,

    /// Filter by created after timestamp
    pub created_after: Option<SystemTime>,

    /// Pagination limit
    pub limit: Option<usize>,

    /// Pagination offset
    pub offset: Option<usize>,
}

/// Session cleanup statistics
#[derive(Debug, Clone)]
pub struct SessionCleanupStats {
    /// Number of sessions removed
    pub removed_count: usize,

    /// Number of sessions remaining
    pub remaining_count: usize,

    /// Bytes freed (estimate)
    pub bytes_freed: u64,

    /// Cleanup duration in milliseconds
    pub duration_ms: u64,
}

/// Session storage port
///
/// Backend-agnostic session persistence with TTL support.
/// Implementations can use Redis, PostgreSQL, or in-memory storage.
#[async_trait]
pub trait SessionStorage: Send + Sync {
    /// Retrieve session by ID
    ///
    /// # Arguments
    ///
    /// * `id` - Session identifier
    ///
    /// # Returns
    ///
    /// * `Ok(Some(session))` - Session found and not expired
    /// * `Ok(None)` - Session not found or expired
    /// * `Err(_)` - Storage backend error
    async fn get_session(&self, id: &str) -> Result<Option<Session>>;

    /// Save or update session
    ///
    /// # Arguments
    ///
    /// * `session` - Session to persist
    ///
    /// # Returns
    ///
    /// * `Ok(())` - Session saved successfully
    /// * `Err(_)` - Storage backend error
    ///
    /// # Behavior
    ///
    /// Automatically updates `last_accessed_at` to current time.
    /// Extends TTL based on backend configuration.
    async fn save_session(&self, session: &Session) -> Result<()>;

    /// Delete session by ID
    ///
    /// # Arguments
    ///
    /// * `id` - Session identifier
    ///
    /// # Returns
    ///
    /// * `Ok(())` - Session deleted (or didn't exist)
    /// * `Err(_)` - Storage backend error
    ///
    /// # Behavior
    ///
    /// Idempotent - deleting non-existent session is not an error.
    async fn delete_session(&self, id: &str) -> Result<()>;

    /// List sessions matching filter
    ///
    /// # Arguments
    ///
    /// * `filter` - Query filter with pagination
    ///
    /// # Returns
    ///
    /// * `Ok(sessions)` - Vector of matching sessions (may be empty)
    /// * `Err(_)` - Storage backend error
    async fn list_sessions(&self, filter: SessionFilter) -> Result<Vec<Session>>;

    /// Remove expired sessions
    ///
    /// # Returns
    ///
    /// * `Ok(count)` - Number of sessions removed
    /// * `Err(_)` - Storage backend error
    ///
    /// # Behavior
    ///
    /// Backends should implement efficient batch deletion.
    /// Called periodically by background cleanup task.
    async fn cleanup_expired(&self) -> Result<usize>;

    /// Get cleanup statistics from last operation
    ///
    /// # Returns
    ///
    /// * `Ok(Some(stats))` - Statistics from last cleanup
    /// * `Ok(None)` - No cleanup has been performed
    async fn get_cleanup_stats(&self) -> Result<Option<SessionCleanupStats>>;

    /// Touch session to extend TTL
    ///
    /// # Arguments
    ///
    /// * `id` - Session identifier
    ///
    /// # Returns
    ///
    /// * `Ok(true)` - Session found and TTL extended
    /// * `Ok(false)` - Session not found or expired
    /// * `Err(_)` - Storage backend error
    ///
    /// # Behavior
    ///
    /// Updates `last_accessed_at` and extends `expires_at` by backend TTL.
    async fn touch_session(&self, id: &str) -> Result<bool> {
        if let Some(mut session) = self.get_session(id).await? {
            session.last_accessed_at = SystemTime::now();
            self.save_session(&session).await?;
            Ok(true)
        } else {
            Ok(false)
        }
    }
}
```

---

### 4.2 Redis SessionStorage Adapter

**File:** `crates/riptide-cache/src/adapters/redis_session_storage.rs`

```rust
//! Redis-backed session storage implementation

use riptide_types::ports::session::{
    Session, SessionFilter, SessionStorage, SessionCleanupStats
};
use riptide_types::error::{Result, RiptideError};
use async_trait::async_trait;
use deadpool_redis::{Pool, redis::AsyncCommands};
use std::time::{SystemTime, Duration};
use std::sync::Arc;
use tokio::sync::RwLock;

/// Redis session storage adapter
pub struct RedisSessionStorage {
    pool: Pool,
    default_ttl_secs: u64,
    max_sessions: usize,
    cleanup_stats: Arc<RwLock<Option<SessionCleanupStats>>>,
}

impl RedisSessionStorage {
    /// Create new Redis session storage
    pub fn new(
        pool: Pool,
        default_ttl_secs: u64,
        max_sessions: usize,
    ) -> Result<Self> {
        Ok(Self {
            pool,
            default_ttl_secs,
            max_sessions,
            cleanup_stats: Arc::new(RwLock::new(None)),
        })
    }

    fn session_key(id: &str) -> String {
        format!("session:{}", id)
    }

    fn sessions_index_key() -> &'static str {
        "sessions:index"
    }
}

#[async_trait]
impl SessionStorage for RedisSessionStorage {
    async fn get_session(&self, id: &str) -> Result<Option<Session>> {
        let mut conn = self.pool.get().await
            .map_err(|e| RiptideError::Storage(e.to_string()))?;

        let key = Self::session_key(id);
        let data: Option<String> = conn.get(&key).await
            .map_err(|e| RiptideError::Storage(e.to_string()))?;

        match data {
            Some(json) => {
                let session: Session = serde_json::from_str(&json)
                    .map_err(|e| RiptideError::Serialization(e.to_string()))?;

                // Check if expired
                if session.expires_at <= SystemTime::now() {
                    // Remove expired session
                    self.delete_session(id).await?;
                    Ok(None)
                } else {
                    Ok(Some(session))
                }
            }
            None => Ok(None),
        }
    }

    async fn save_session(&self, session: &Session) -> Result<()> {
        let mut conn = self.pool.get().await
            .map_err(|e| RiptideError::Storage(e.to_string()))?;

        // Update last accessed time
        let mut session = session.clone();
        session.last_accessed_at = SystemTime::now();
        session.expires_at = SystemTime::now() + Duration::from_secs(self.default_ttl_secs);

        // Serialize session
        let json = serde_json::to_string(&session)
            .map_err(|e| RiptideError::Serialization(e.to_string()))?;

        // Save with TTL
        let key = Self::session_key(&session.id);
        conn.set_ex(&key, json, self.default_ttl_secs as usize).await
            .map_err(|e| RiptideError::Storage(e.to_string()))?;

        // Add to index
        conn.sadd(Self::sessions_index_key(), &session.id).await
            .map_err(|e| RiptideError::Storage(e.to_string()))?;

        Ok(())
    }

    async fn delete_session(&self, id: &str) -> Result<()> {
        let mut conn = self.pool.get().await
            .map_err(|e| RiptideError::Storage(e.to_string()))?;

        let key = Self::session_key(id);
        conn.del(&key).await
            .map_err(|e| RiptideError::Storage(e.to_string()))?;

        // Remove from index
        conn.srem(Self::sessions_index_key(), id).await
            .map_err(|e| RiptideError::Storage(e.to_string()))?;

        Ok(())
    }

    async fn list_sessions(&self, filter: SessionFilter) -> Result<Vec<Session>> {
        let mut conn = self.pool.get().await
            .map_err(|e| RiptideError::Storage(e.to_string()))?;

        // Get all session IDs from index
        let session_ids: Vec<String> = conn.smembers(Self::sessions_index_key()).await
            .map_err(|e| RiptideError::Storage(e.to_string()))?;

        let mut sessions = Vec::new();
        for id in session_ids {
            if let Some(session) = self.get_session(&id).await? {
                // Apply filters
                if filter.active_only && session.expires_at <= SystemTime::now() {
                    continue;
                }
                if let Some(ref user_id) = filter.user_id {
                    if session.user_id.as_ref() != Some(user_id) {
                        continue;
                    }
                }
                if let Some(created_after) = filter.created_after {
                    if session.created_at < created_after {
                        continue;
                    }
                }

                sessions.push(session);
            }
        }

        // Apply pagination
        let offset = filter.offset.unwrap_or(0);
        let limit = filter.limit.unwrap_or(usize::MAX);

        Ok(sessions.into_iter().skip(offset).take(limit).collect())
    }

    async fn cleanup_expired(&self) -> Result<usize> {
        let start = std::time::Instant::now();
        let mut removed_count = 0;

        // Get all session IDs
        let mut conn = self.pool.get().await
            .map_err(|e| RiptideError::Storage(e.to_string()))?;
        let session_ids: Vec<String> = conn.smembers(Self::sessions_index_key()).await
            .map_err(|e| RiptideError::Storage(e.to_string()))?;

        drop(conn);

        // Check each session for expiration
        for id in &session_ids {
            if let Some(session) = self.get_session(id).await? {
                if session.expires_at <= SystemTime::now() {
                    self.delete_session(id).await?;
                    removed_count += 1;
                }
            }
        }

        // Calculate remaining sessions
        let mut conn = self.pool.get().await
            .map_err(|e| RiptideError::Storage(e.to_string()))?;
        let remaining_count: usize = conn.scard(Self::sessions_index_key()).await
            .map_err(|e| RiptideError::Storage(e.to_string()))?;

        let duration_ms = start.elapsed().as_millis() as u64;
        let stats = SessionCleanupStats {
            removed_count,
            remaining_count,
            bytes_freed: (removed_count * 8192) as u64, // Estimate
            duration_ms,
        };

        *self.cleanup_stats.write().await = Some(stats.clone());

        Ok(removed_count)
    }

    async fn get_cleanup_stats(&self) -> Result<Option<SessionCleanupStats>> {
        Ok(self.cleanup_stats.read().await.clone())
    }
}
```

---

## Sprint 1.5: Infrastructure Ports

### Overview

Define port traits for HTTP client, metrics collection, health checks, and RPC communication.

---

### 5.1 HttpClient Port

**File:** `crates/riptide-types/src/ports/http.rs`

```rust
//! HTTP client port for backend-agnostic HTTP requests

use crate::error::Result;
use async_trait::async_trait;
use std::collections::HashMap;
use std::time::Duration;

/// HTTP method
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum HttpMethod {
    GET,
    POST,
    PUT,
    PATCH,
    DELETE,
    HEAD,
    OPTIONS,
}

/// HTTP request
#[derive(Debug, Clone)]
pub struct HttpRequest {
    pub method: HttpMethod,
    pub url: String,
    pub headers: HashMap<String, String>,
    pub body: Option<Vec<u8>>,
    pub timeout: Option<Duration>,
}

/// HTTP response
#[derive(Debug, Clone)]
pub struct HttpResponse {
    pub status: u16,
    pub headers: HashMap<String, String>,
    pub body: Vec<u8>,
}

/// HTTP client port
///
/// Backend-agnostic HTTP client abstraction.
/// Implementations can use reqwest, hyper, or custom backends.
#[async_trait]
pub trait HttpClient: Send + Sync {
    /// Execute HTTP request
    ///
    /// # Arguments
    ///
    /// * `request` - HTTP request to execute
    ///
    /// # Returns
    ///
    /// * `Ok(response)` - HTTP response received
    /// * `Err(_)` - Network error, timeout, or backend error
    async fn execute(&self, request: HttpRequest) -> Result<HttpResponse>;

    /// Execute GET request
    async fn get(&self, url: &str) -> Result<HttpResponse> {
        self.execute(HttpRequest {
            method: HttpMethod::GET,
            url: url.to_string(),
            headers: HashMap::new(),
            body: None,
            timeout: None,
        }).await
    }

    /// Execute POST request with JSON body
    async fn post_json(&self, url: &str, body: serde_json::Value) -> Result<HttpResponse> {
        let json = serde_json::to_vec(&body)?;
        let mut headers = HashMap::new();
        headers.insert("Content-Type".to_string(), "application/json".to_string());

        self.execute(HttpRequest {
            method: HttpMethod::POST,
            url: url.to_string(),
            headers,
            body: Some(json),
            timeout: None,
        }).await
    }
}
```

---

### 5.2 MetricsCollector Port

**File:** `crates/riptide-types/src/ports/metrics.rs`

```rust
//! Metrics collection port for observability

use crate::error::Result;
use async_trait::async_trait;
use std::time::Instant;

/// Metric type
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum MetricType {
    Counter,
    Gauge,
    Histogram,
}

/// Metric labels
pub type MetricLabels = Vec<(String, String)>;

/// Metrics collector port
///
/// Backend-agnostic metrics collection.
/// Implementations can use Prometheus, StatsD, or custom backends.
#[async_trait]
pub trait MetricsCollector: Send + Sync {
    /// Increment counter metric
    ///
    /// # Arguments
    ///
    /// * `name` - Metric name
    /// * `value` - Value to increment by (default: 1)
    /// * `labels` - Optional metric labels
    fn increment_counter(
        &self,
        name: &str,
        value: f64,
        labels: Option<MetricLabels>,
    );

    /// Set gauge metric
    ///
    /// # Arguments
    ///
    /// * `name` - Metric name
    /// * `value` - Gauge value
    /// * `labels` - Optional metric labels
    fn set_gauge(
        &self,
        name: &str,
        value: f64,
        labels: Option<MetricLabels>,
    );

    /// Record histogram observation
    ///
    /// # Arguments
    ///
    /// * `name` - Metric name
    /// * `value` - Observation value
    /// * `labels` - Optional metric labels
    fn observe_histogram(
        &self,
        name: &str,
        value: f64,
        labels: Option<MetricLabels>,
    );

    /// Record duration histogram
    ///
    /// # Arguments
    ///
    /// * `name` - Metric name
    /// * `start` - Start instant
    /// * `labels` - Optional metric labels
    fn record_duration(
        &self,
        name: &str,
        start: Instant,
        labels: Option<MetricLabels>,
    ) {
        let duration = start.elapsed();
        self.observe_histogram(name, duration.as_secs_f64(), labels);
    }
}

/// Timer helper for automatic duration tracking
pub struct MetricTimer<'a> {
    collector: &'a dyn MetricsCollector,
    name: String,
    labels: Option<MetricLabels>,
    start: Instant,
}

impl<'a> MetricTimer<'a> {
    pub fn new(
        collector: &'a dyn MetricsCollector,
        name: impl Into<String>,
        labels: Option<MetricLabels>,
    ) -> Self {
        Self {
            collector,
            name: name.into(),
            labels,
            start: Instant::now(),
        }
    }
}

impl<'a> Drop for MetricTimer<'a> {
    fn drop(&mut self) {
        self.collector.record_duration(&self.name, self.start, self.labels.clone());
    }
}
```

---

### 5.3 HealthCheck Port

**File:** `crates/riptide-types/src/ports/health.rs`

```rust
//! Health check port for service monitoring

use crate::error::Result;
use async_trait::async_trait;
use std::collections::HashMap;
use std::future::Future;
use std::pin::Pin;

/// Health status
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum HealthStatus {
    Healthy,
    Unhealthy,
    Degraded,
}

/// Health check result
#[derive(Debug, Clone)]
pub struct HealthCheckResult {
    pub status: HealthStatus,
    pub message: Option<String>,
    pub details: HashMap<String, serde_json::Value>,
}

/// Health check function
pub type HealthCheckFn = Box<
    dyn Fn() -> Pin<Box<dyn Future<Output = HealthStatus> + Send>>
        + Send
        + Sync
>;

/// Individual health check
#[async_trait]
pub trait HealthCheck: Send + Sync {
    /// Perform health check
    ///
    /// # Returns
    ///
    /// * `Ok(result)` - Health check completed
    /// * `Err(_)` - Health check failed to execute
    async fn check(&self) -> Result<HealthCheckResult>;

    /// Get health check name
    fn name(&self) -> &str;
}

/// Health registry for managing multiple health checks
#[async_trait]
pub trait HealthRegistry: Send + Sync {
    /// Register health check
    ///
    /// # Arguments
    ///
    /// * `name` - Health check identifier
    /// * `check` - Health check function
    async fn register(&self, name: &str, check: HealthCheckFn);

    /// Unregister health check
    ///
    /// # Arguments
    ///
    /// * `name` - Health check identifier
    async fn unregister(&self, name: &str);

    /// Check overall system health
    ///
    /// # Returns
    ///
    /// Overall health status (healthy only if all checks pass)
    async fn check_all(&self) -> Result<HashMap<String, HealthCheckResult>>;

    /// Check specific health check
    ///
    /// # Arguments
    ///
    /// * `name` - Health check identifier
    ///
    /// # Returns
    ///
    /// * `Ok(Some(result))` - Health check found
    /// * `Ok(None)` - Health check not found
    async fn check_one(&self, name: &str) -> Result<Option<HealthCheckResult>>;
}
```

---

### 5.4 RpcClient Port

**File:** `crates/riptide-types/src/ports/rpc.rs`

```rust
//! RPC client port for service-to-service communication

use crate::error::Result;
use async_trait::async_trait;
use serde::{Deserialize, Serialize};
use std::time::Duration;

/// RPC request
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RpcRequest {
    /// Service name
    pub service: String,

    /// Method name
    pub method: String,

    /// Request parameters (JSON)
    pub params: serde_json::Value,

    /// Request timeout
    #[serde(skip)]
    pub timeout: Option<Duration>,
}

/// RPC response
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RpcResponse {
    /// Response data (JSON)
    pub result: Option<serde_json::Value>,

    /// Error message if request failed
    pub error: Option<String>,
}

/// RPC client port
///
/// Backend-agnostic RPC communication.
/// Implementations can use gRPC, JSON-RPC, or custom protocols.
#[async_trait]
pub trait RpcClient: Send + Sync {
    /// Execute RPC call
    ///
    /// # Arguments
    ///
    /// * `request` - RPC request
    ///
    /// # Returns
    ///
    /// * `Ok(response)` - RPC response received
    /// * `Err(_)` - Network error, timeout, or RPC error
    async fn call(&self, request: RpcRequest) -> Result<RpcResponse>;

    /// Execute typed RPC call with automatic serialization
    ///
    /// # Arguments
    ///
    /// * `service` - Service name
    /// * `method` - Method name
    /// * `params` - Request parameters (will be serialized to JSON)
    ///
    /// # Returns
    ///
    /// * `Ok(result)` - Deserialized response
    /// * `Err(_)` - Network error, timeout, RPC error, or deserialization error
    async fn call_typed<Req, Res>(
        &self,
        service: &str,
        method: &str,
        params: &Req,
    ) -> Result<Res>
    where
        Req: Serialize + Send + Sync,
        Res: for<'de> Deserialize<'de> + Send;
}
```

---

## Configuration Schema

### TOML Configuration File

**File:** `config/production.toml`

```toml
# Riptide Production Configuration

[database]
url = "postgres://user:password@localhost:5432/riptide"
max_connections = 20
min_connections = 5
acquire_timeout_secs = 10

[cache]
redis_url = "redis://localhost:6379/0"
max_connections = 10
default_ttl_secs = 3600

[sessions]
storage_backend = "redis"  # Options: "redis", "disk", "memory"
redis_url = "redis://localhost:6379/1"
base_data_dir = "/var/lib/riptide/sessions"  # Used for "disk" backend
default_ttl_secs = 86400  # 24 hours
max_sessions = 10000
cleanup_interval_secs = 300  # 5 minutes

[features]
enable_browser = true
enable_pdf = true
enable_search = true

[infrastructure]
http_timeout_secs = 30
max_retries = 3

[observability]
metrics_port = 9090
health_check_port = 9091
enable_tracing = true
```

### Environment Variable Overrides

```bash
# Database
DATABASE_URL="postgres://..."
DATABASE_MAX_CONNECTIONS=20

# Cache
REDIS_URL="redis://..."
CACHE_DEFAULT_TTL_SECS=3600

# Sessions
SESSION_STORAGE_BACKEND="redis"
SESSION_REDIS_URL="redis://..."
SESSION_TTL_SECS=86400
SESSION_MAX_SESSIONS=10000

# Features
ENABLE_BROWSER=true
ENABLE_PDF=true
ENABLE_SEARCH=true

# Observability
METRICS_PORT=9090
HEALTH_CHECK_PORT=9091
ENABLE_TRACING=true
```

---

## Adapter Mapping Table

| **Port Trait**          | **Crate**         | **Production Adapter**          | **Test Adapter**             | **Feature Flag** |
|-------------------------|-------------------|---------------------------------|------------------------------|------------------|
| `Repository<T>`         | `riptide-types`   | `PostgresRepository`            | `InMemoryRepository`         | `postgres`       |
| `TransactionManager`    | `riptide-types`   | `PostgresTransactionManager`    | `NoOpTransactionManager`     | `postgres`       |
| `EventBus`              | `riptide-types`   | `OutboxEventBus`                | `InMemoryEventBus`           | `postgres`       |
| `IdempotencyStore`      | `riptide-types`   | `RedisIdempotencyStore`         | `InMemoryIdempotencyStore`   | `redis`          |
| `CacheStorage`          | `riptide-types`   | `RedisCache`                    | `InMemoryCache`              | `redis`          |
| `SessionStorage`        | `riptide-types`   | `RedisSessionStorage`           | `InMemorySessionStorage`     | `redis`          |
| `BrowserDriver`         | `riptide-types`   | `ChromeDriver` (chromiumoxide)  | `MockBrowserDriver`          | `browser`        |
| `PdfProcessor`          | `riptide-types`   | `PopplerPdfProcessor`           | `MockPdfProcessor`           | `pdf`            |
| `SearchEngine`          | `riptide-types`   | `MeiliSearchEngine`             | `MockSearchEngine`           | `search`         |
| `Clock`                 | `riptide-types`   | `SystemClock`                   | `FakeClock`                  | (none)           |
| `Entropy`               | `riptide-types`   | `SystemEntropy`                 | `DeterministicEntropy`       | (none)           |
| `HttpClient`            | `riptide-types`   | `ReqwestHttpClient`             | `MockHttpClient`             | `http`           |
| `MetricsCollector`      | `riptide-types`   | `PrometheusMetricsCollector`    | `NoOpMetricsCollector`       | `metrics`        |
| `HealthRegistry`        | `riptide-types`   | `DefaultHealthRegistry`         | `DefaultHealthRegistry`      | (none)           |
| `RpcClient`             | `riptide-types`   | `GrpcClient`                    | `MockRpcClient`              | `grpc`           |

---

## Testing Strategy

### Unit Testing with In-Memory Adapters

```rust
#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_session_crud() {
        // Use in-memory adapters for fast unit tests
        let ctx = ApplicationContext::for_testing();
        let session_storage = ctx.session_storage();

        // Create session
        let session = Session {
            id: "test-session".to_string(),
            user_id: Some("user-123".to_string()),
            created_at: SystemTime::now(),
            last_accessed_at: SystemTime::now(),
            expires_at: SystemTime::now() + Duration::from_secs(3600),
            metadata: serde_json::json!({"test": true}),
            user_data_dir: None,
        };

        session_storage.save_session(&session).await.unwrap();

        // Retrieve session
        let retrieved = session_storage
            .get_session("test-session")
            .await
            .unwrap();

        assert!(retrieved.is_some());
        assert_eq!(retrieved.unwrap().id, "test-session");

        // Delete session
        session_storage.delete_session("test-session").await.unwrap();
        let deleted = session_storage
            .get_session("test-session")
            .await
            .unwrap();

        assert!(deleted.is_none());
    }

    #[tokio::test]
    async fn test_deterministic_clock() {
        let ctx = ApplicationContext::for_testing();
        let clock = ctx.clock();

        // In testing context, clock is FakeClock
        let timestamp1 = clock.timestamp();

        // Time doesn't advance unless explicitly set
        let timestamp2 = clock.timestamp();
        assert_eq!(timestamp1, timestamp2);
    }
}
```

### Integration Testing with Testcontainers

```rust
#[cfg(test)]
mod integration_tests {
    use testcontainers::{clients, images};

    #[tokio::test]
    async fn test_postgres_repository() {
        // Start PostgreSQL in Docker container
        let docker = clients::Cli::default();
        let postgres = docker.run(images::postgres::Postgres::default());
        let port = postgres.get_host_port_ipv4(5432);

        // Create ApplicationContext with test database
        let config = AppConfig {
            database: DatabaseConfig {
                url: format!("postgres://postgres@localhost:{}/test", port),
                max_connections: 5,
                min_connections: 1,
                acquire_timeout_secs: 5,
            },
            // ... other config
        };

        let ctx = ApplicationContext::build(config).await.unwrap();

        // Test repository operations against real PostgreSQL
        // ...
    }
}
```

---

## Migration Path

### Phase 1: Extract Existing Code to Ports (Sprint 1.4)

1. **Create SessionStorage port trait** in `riptide-types/src/ports/session.rs`
2. **Move Session types** from `riptide-api/src/sessions/types.rs` to port module
3. **Implement InMemorySessionStorage** adapter by refactoring existing `SessionStorage` in `riptide-api`
4. **Keep existing implementation** but make it implement new port trait
5. **Update tests** to use new port trait

### Phase 2: Create Redis Adapter (Sprint 1.4)

1. **Implement RedisSessionStorage** in `riptide-cache/src/adapters/`
2. **Add feature flag** `sessions-redis` to enable Redis backend
3. **Add integration tests** with testcontainers-redis
4. **Document Redis schema** (key format, TTL strategy)

### Phase 3: Build ApplicationContext (Sprint 1.3)

1. **Create `composition.rs`** in `riptide-api/src/`
2. **Implement builder pattern** for configuration-driven construction
3. **Add TOML parser** with `toml` crate
4. **Wire all existing adapters** to ApplicationContext
5. **Replace manual construction** in `main.rs` with ApplicationContext

### Phase 4: Add Infrastructure Ports (Sprint 1.5)

1. **Define port traits** in `riptide-types/src/ports/`
2. **Implement production adapters**:
   - `ReqwestHttpClient` for HTTP
   - `PrometheusMetricsCollector` for metrics
   - `DefaultHealthRegistry` for health checks
   - `GrpcClient` for RPC (future)
3. **Integrate into ApplicationContext**
4. **Add observability endpoints** (`/metrics`, `/health`)

### Phase 5: Refactor Existing Code (Post-Sprint 1.5)

1. **Replace direct dependencies** with port traits
2. **Remove concrete types** from domain layer
3. **Update dependency injection** to use ApplicationContext
4. **Migrate tests** to use in-memory adapters
5. **Remove legacy infrastructure code**

---

## Architecture Diagrams

### System Context Diagram (C4 Level 1)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Riptide System                       â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              ApplicationContext (DI)                  â”‚ â”‚
â”‚  â”‚                                                       â”‚ â”‚
â”‚  â”‚  Ports (Interfaces)           Adapters (Impl)        â”‚ â”‚
â”‚  â”‚  â”œâ”€ Repository<T>        â†’    PostgresRepository     â”‚ â”‚
â”‚  â”‚  â”œâ”€ EventBus             â†’    OutboxEventBus         â”‚ â”‚
â”‚  â”‚  â”œâ”€ IdempotencyStore     â†’    RedisIdempotency       â”‚ â”‚
â”‚  â”‚  â”œâ”€ SessionStorage       â†’    RedisSessionStorage    â”‚ â”‚
â”‚  â”‚  â”œâ”€ CacheStorage         â†’    RedisCache             â”‚ â”‚
â”‚  â”‚  â”œâ”€ HttpClient           â†’    ReqwestHttpClient      â”‚ â”‚
â”‚  â”‚  â”œâ”€ MetricsCollector     â†’    PrometheusMetrics      â”‚ â”‚
â”‚  â”‚  â””â”€ HealthRegistry       â†’    DefaultHealthRegistry  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                  â”‚                   â”‚
         â–¼                  â–¼                   â–¼
   PostgreSQL 15        Redis 7.0         Prometheus
```

### ApplicationContext Wiring Diagram (C4 Level 2)

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   config.toml / ENV vars    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  ApplicationContext::build  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                       â”‚                       â”‚
           â–¼                       â–¼                       â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Create Poolsâ”‚        â”‚Create Ports â”‚        â”‚  Register   â”‚
    â”‚             â”‚        â”‚             â”‚        â”‚ Health Chks â”‚
    â”‚ - Postgres  â”‚        â”‚ - Repositoryâ”‚        â”‚             â”‚
    â”‚ - Redis     â”‚        â”‚ - EventBus  â”‚        â”‚ - Postgres  â”‚
    â”‚             â”‚        â”‚ - Session   â”‚        â”‚ - Redis     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                       â”‚                       â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   ApplicationContext (Arc)  â”‚
                    â”‚                             â”‚
                    â”‚ - postgres_pool             â”‚
                    â”‚ - redis_pool                â”‚
                    â”‚ - event_bus                 â”‚
                    â”‚ - session_storage           â”‚
                    â”‚ - cache                     â”‚
                    â”‚ - http_client               â”‚
                    â”‚ - metrics                   â”‚
                    â”‚ - health                    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Hexagonal Architecture Layers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        HTTP Layer (Axum)                      â”‚
â”‚  /sessions, /metrics, /health, /crawl, /render, /llm         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Application Layer (API)                    â”‚
â”‚  SessionManager, CrawlService, RenderService, LLMService      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼ (depends on port traits)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Domain Layer (Types)                     â”‚
â”‚  Port Traits: Repository, EventBus, SessionStorage,           â”‚
â”‚  IdempotencyStore, CacheStorage, HttpClient, Metrics          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼ (implemented by adapters)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Infrastructure Layer (Adapters)               â”‚
â”‚  PostgresRepository, RedisSessionStorage, OutboxEventBus,     â”‚
â”‚  ReqwestHttpClient, PrometheusMetricsCollector                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     External Systems                          â”‚
â”‚  PostgreSQL, Redis, Prometheus, HTTP APIs                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Acceptance Criteria

### Sprint 1.3: ApplicationContext

- [ ] ApplicationContext struct implemented with builder pattern
- [ ] Configuration loading from TOML file
- [ ] Configuration loading from environment variables
- [ ] Pool management for PostgreSQL and Redis
- [ ] All existing adapters wired correctly
- [ ] `for_testing()` factory with in-memory adapters
- [ ] Health checks registered for all infrastructure components
- [ ] Integration tests with testcontainers
- [ ] Documentation in rustdoc format
- [ ] Zero compilation warnings

### Sprint 1.4: SessionStorage Port

- [ ] SessionStorage port trait defined in `riptide-types`
- [ ] Session, SessionFilter, SessionCleanupStats types moved to port
- [ ] InMemorySessionStorage adapter implemented
- [ ] RedisSessionStorage adapter implemented
- [ ] Redis key schema documented
- [ ] TTL and expiration handled correctly
- [ ] Cleanup operations efficient (batch deletion)
- [ ] Unit tests for both adapters
- [ ] Integration tests with testcontainers-redis
- [ ] Migration guide for existing session code

### Sprint 1.5: Infrastructure Ports

- [ ] HttpClient port trait with reqwest adapter
- [ ] MetricsCollector port trait with Prometheus adapter
- [ ] HealthRegistry port trait with default implementation
- [ ] RpcClient port trait (stub for future use)
- [ ] Mock adapters for all ports (testing)
- [ ] Observability endpoints (`/metrics`, `/health`)
- [ ] Integration with ApplicationContext
- [ ] Performance benchmarks for HTTP client
- [ ] Prometheus metrics exposed correctly
- [ ] Health check aggregation logic

---

## Risk Assessment

| **Risk**                              | **Impact** | **Probability** | **Mitigation**                                      |
|---------------------------------------|------------|-----------------|-----------------------------------------------------|
| Breaking existing session code        | High       | Medium          | Incremental migration, keep existing code working   |
| Redis connection pool exhaustion      | High       | Low             | Connection limits, health checks, circuit breakers  |
| Configuration parsing errors          | Medium     | Medium          | Comprehensive validation, sane defaults             |
| Performance regression                | High       | Low             | Benchmarking, profiling, load testing               |
| Test coverage gaps                    | Medium     | Medium          | Code coverage tracking, integration test suite      |
| Circular dependencies                 | High       | Low             | Strict layering, dependency graph validation        |

---

## Performance Considerations

1. **Connection Pooling**: Use `deadpool` for PostgreSQL and Redis to avoid connection overhead
2. **Lazy Initialization**: Features (browser, PDF, search) only initialized when enabled
3. **Health Check Caching**: Cache health check results for 10 seconds to avoid overwhelming infrastructure
4. **Metrics Batching**: Batch metrics updates to reduce Prometheus overhead
5. **Session Cleanup**: Run cleanup in background task, not on critical path
6. **Configuration Caching**: Parse configuration once at startup, cache in memory

---

## Security Considerations

1. **Secrets Management**: Never log configuration values, use secret management for production
2. **Connection Strings**: Store credentials in environment variables, not TOML files
3. **Session TTL**: Enforce maximum session lifetime to prevent session fixation
4. **Health Endpoints**: Restrict access to health/metrics endpoints in production
5. **SQL Injection**: Use parameterized queries in all repository adapters
6. **Redis Security**: Use password authentication, TLS for production Redis

---

## Conclusion

This architecture design provides:
- âœ… **Strict hexagonal architecture** with port/adapter separation
- âœ… **Dependency injection** via ApplicationContext composition root
- âœ… **Configuration-driven** construction from TOML/ENV
- âœ… **Testability** with in-memory adapters for unit tests
- âœ… **Observability** with Prometheus metrics and health checks
- âœ… **Type safety** with compile-time dependency resolution
- âœ… **Extensibility** for future adapters (MongoDB, gRPC, etc.)

**Architecture Compliance Score: 95/100**

Deviations from perfect score:
- -3 points: Some existing session code tightly coupled to concrete types (will be fixed in refactoring)
- -2 points: Feature detection adapters not yet implemented (future work)

**Next Steps:**
1. Review this design document with team
2. Create implementation tasks in project board
3. Begin Sprint 1.3 with ApplicationContext implementation
4. Parallel track: Extract SessionStorage port while building ApplicationContext
5. Complete Sprint 1.5 infrastructure ports last (lowest risk)

---

**Document Version:** 1.0
**Last Updated:** 2025-11-08
**Status:** Ready for Implementation
