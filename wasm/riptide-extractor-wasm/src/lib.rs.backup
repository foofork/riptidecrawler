use once_cell::sync::Lazy;
use std::sync::atomic::{AtomicU64, Ordering};
use std::collections::HashMap;
use trek_rs::{Article, Extractor as TrekExtractor, ExtractorConfig};

mod trek_helpers;
use trek_helpers::*;

// Generate bindings from enhanced WIT file
wit_bindgen::generate!({
    world: "extractor",
    path: "wit",
});

// Export the Component Model interface
export!(Component);

/// Global extraction counter for tracking component usage
static EXTRACTION_COUNT: Lazy<AtomicU64> = Lazy::new(|| AtomicU64::new(0));

/// Component state for caching and metrics
static COMPONENT_STATE: Lazy<std::sync::Mutex<ComponentState>> = Lazy::new(|| {
    std::sync::Mutex::new(ComponentState::new())
});

/// Internal component state
struct ComponentState {
    extractor_cache: HashMap<String, TrekExtractor>,
    memory_usage: u64,
    start_time: std::time::Instant,
}

impl ComponentState {
    fn new() -> Self {
        Self {
            extractor_cache: HashMap::new(),
            memory_usage: 0,
            start_time: std::time::Instant::now(),
        }
    }

    fn get_or_create_extractor(&mut self, mode: &ExtractionMode) -> TrekExtractor {
        let key = mode_to_cache_key(mode);

        if let Some(extractor) = self.extractor_cache.get(&key) {
            return extractor.clone();
        }

        let config = match mode {
            ExtractionMode::Article => ExtractorConfig::new()
                .with_readability(true)
                .with_metadata(true)
                .with_links(true),
            ExtractionMode::Full => ExtractorConfig::new()
                .with_full_content(true)
                .with_navigation(true)
                .with_sidebars(true),
            ExtractionMode::Metadata => ExtractorConfig::new()
                .with_metadata_only(true)
                .with_structured_data(true),
            ExtractionMode::Custom(selectors) => ExtractorConfig::new()
                .with_custom_selectors(selectors.clone()),
        };

        let extractor = TrekExtractor::with_config(config);
        self.extractor_cache.insert(key, extractor.clone());
        extractor
    }
}

/// Convert extraction mode to cache key
fn mode_to_cache_key(mode: &ExtractionMode) -> String {
    match mode {
        ExtractionMode::Article => "article".to_string(),
        ExtractionMode::Full => "full".to_string(),
        ExtractionMode::Metadata => "metadata".to_string(),
        ExtractionMode::Custom(selectors) => {
            format!("custom:{}", selectors.join(","))
        }
    }
}

/// Component build information
const COMPONENT_VERSION: &str = env!("CARGO_PKG_VERSION");
const COMPONENT_NAME: &str = env!("CARGO_PKG_NAME");

/// Get build timestamp with fallback
fn get_build_timestamp() -> &'static str {
    option_env!("VERGEN_BUILD_TIMESTAMP").unwrap_or("unknown")
}

/// Get git commit with fallback
fn get_git_commit() -> &'static str {
    option_env!("VERGEN_GIT_SHA").unwrap_or("unknown")
}

struct Component;

impl Guest for Component {
    /// Primary extraction function with enhanced error handling and trek-rs integration
    fn extract(
        html: String,
        url: String,
        mode: ExtractionMode,
    ) -> Result<ExtractedContent, ExtractionError> {
        let start_time = std::time::Instant::now();

        // Increment extraction counter
        EXTRACTION_COUNT.fetch_add(1, Ordering::Relaxed);

        // Validate HTML input
        if html.trim().is_empty() {
            return Err(ExtractionError::InvalidHtml(
                "Empty HTML content".to_string(),
            ));
        }

        // Validate URL format
        if url::Url::parse(&url).is_err() {
            return Err(ExtractionError::InvalidHtml(
                "Invalid URL format".to_string(),
            ));
        }

        // Perform extraction with trek-rs
        perform_extraction_with_trek(&html, &url, &mode)
    }

    /// Extract content with detailed performance statistics
    fn extract_with_stats(
        html: String,
        url: String,
        mode: ExtractionMode,
    ) -> Result<(ExtractedContent, ExtractionStats), ExtractionError> {
        let start_time = std::time::Instant::now();
        let initial_memory = get_memory_usage();

        let content = Self::extract(html.clone(), url, mode)?;

        let processing_time = start_time.elapsed().as_millis() as u64;
        let memory_used = get_memory_usage().saturating_sub(initial_memory);
        let links_found = content.links.len() as u32;
        let images_found = content.media.len() as u32;

        // Count DOM nodes (approximate)
        let nodes_processed = Some(count_html_nodes(&html));

        let stats = ExtractionStats {
            processing_time_ms: processing_time,
            memory_used,
            nodes_processed,
            links_found,
            images_found,
        };

        Ok((content, stats))
    }

    /// Validate HTML content without full extraction
    fn validate_html(html: String) -> Result<bool, ExtractionError> {
        if html.trim().is_empty() {
            return Ok(false);
        }

        // Basic HTML validation
        let html_lower = html.to_lowercase();
        let has_html_tags = html_lower.contains("<html") || html_lower.contains("<!doctype");
        let has_body = html_lower.contains("<body");
        let has_content_tags = html_lower.contains("<p>")
            || html_lower.contains("<div")
            || html_lower.contains("<article")
            || html_lower.contains("<main");

        Ok(has_html_tags && (has_body || has_content_tags))
    }

    /// Health check for component monitoring
    fn health_check() -> HealthStatus {
        HealthStatus {
            status: "healthy".to_string(),
            version: COMPONENT_VERSION.to_string(),
            trek_version: get_trek_version(),
        }
            capabilities: get_supported_modes(),
            memory_usage: Some(get_memory_usage()),
            extraction_count: Some(EXTRACTION_COUNT.load(Ordering::Relaxed)),
        }
    }

    /// Get detailed component information
    fn get_info() -> ComponentInfo {
        ComponentInfo {
            name: COMPONENT_NAME.to_string(),
            version: COMPONENT_VERSION.to_string(),
            component_model_version: "0.2.0".to_string(),
            features: vec![
                "article-extraction".to_string(),
                "full-page-extraction".to_string(),
                "metadata-extraction".to_string(),
                "custom-selectors".to_string(),
                "trek-rs-integration".to_string(),
            ],
            supported_modes: get_supported_modes(),
            build_timestamp: Some(get_build_timestamp().to_string()),
            git_commit: Some(get_git_commit().to_string()),
        }
    }

    /// Reset component state and clear caches
    fn reset_state() -> Result<String, ExtractionError> {
        // Reset extraction counter
        EXTRACTION_COUNT.store(0, Ordering::Relaxed);

        // Clear caches and reset state
        if let Ok(mut state) = COMPONENT_STATE.lock() {
            let old_count = EXTRACTION_COUNT.load(Ordering::Relaxed);
            state.extractor_cache.clear();
            state.memory_usage = 0;
            EXTRACTION_COUNT.store(0, Ordering::Relaxed);
            Ok(format!("Component state reset successfully. Previous extraction count: {}", old_count))
        } else {
            Err(ExtractionError::InternalError("Failed to acquire state lock".to_string()))
        }
    }

    /// Get supported extraction modes
    fn get_modes() -> Vec<String> {
        get_supported_modes()
    }
}

/// Perform content extraction with trek-rs integration
fn perform_extraction_with_trek(
    html: &str,
    url: &str,
    mode: &ExtractionMode,
) -> Result<ExtractedContent, ExtractionError> {
    // Get or create an extractor for this mode
    let mut extractor = {
        match COMPONENT_STATE.lock() {
            Ok(mut state) => state.get_or_create_extractor(mode),
            Err(_) => {
                return Err(ExtractionError::InternalError(
                    "Failed to acquire component state lock".to_string(),
                ));
            }
        }
    };

    // Perform extraction using trek-rs
    let article = match extractor.url(url).html(html).extract() {
        Ok(article) => article,
        Err(trek_error) => {
            return Err(ExtractionError::ExtractorError(
                format!("Trek extraction failed: {}", trek_error),
            ));
        }
    };

    // Convert trek-rs result to Component Model format
    convert_article_to_content(article, url, mode)
}

/// Convert trek-rs Article to Component Model ExtractedContent
fn convert_article_to_content(
    article: Article,
    url: &str,
    mode: &ExtractionMode,
) -> Result<ExtractedContent, ExtractionError> {
    // Calculate quality score based on content richness
    let quality_score = calculate_quality_score(&article);
    let word_count = count_words(&article.content_text);
    let reading_time = estimate_reading_time(&article.content_text);

    Ok(ExtractedContent {
        url: url.to_string(),
        title: article.title,
        byline: article.byline,
        published_iso: article.published_time.map(|t| t.to_rfc3339()),
        markdown: article.content_markdown.unwrap_or_default(),
        text: article.content_text.clone(),
        links: article.links.unwrap_or_default(),
        media: article.images.unwrap_or_default(),
        language: article.language,
        reading_time,
        quality_score: Some(quality_score),
        word_count: Some(word_count),
        categories: article.tags.unwrap_or_default(),
        site_name: article.site_name,
        description: article.description,
    })
}

/// Get supported extraction modes
fn get_supported_modes() -> Vec<String> {
    vec![
        "article - Extract article content using readability algorithms".to_string(),
        "full - Extract full page content including sidebars and navigation".to_string(),
        "metadata - Extract only metadata (title, description, structured data)".to_string(),
        "custom - Custom extraction using provided CSS selectors".to_string(),
    ]
}

/// Estimate memory usage (simplified implementation)
fn get_memory_usage() -> u64 {
    // In a real implementation, this would use platform-specific APIs
    // For now, return a placeholder value
    1024 * 1024 // 1MB placeholder
}

/// Count HTML nodes for statistics
fn count_html_nodes(html: &str) -> u32 {
    // Simple node counting by counting opening tags
    html.matches('<').count() as u32
}

/// Detect content language (simplified implementation)
fn detect_language(text: &str) -> Option<String> {
    // Simple language detection based on common words
    // In a real implementation, use a proper language detection library
    let common_english = ["the", "and", "for", "are", "but", "not", "you", "all"];
    let common_spanish = ["el", "la", "de", "que", "y", "a", "en", "un"];
    let common_french = ["le", "de", "et", "à", "un", "il", "être", "et"];

    let text_lower = text.to_lowercase();
    let words: Vec<&str> = text_lower.split_whitespace().take(100).collect();

    let english_score = common_english
        .iter()
        .filter(|&&word| words.contains(&word))
        .count();
    let spanish_score = common_spanish
        .iter()
        .filter(|&&word| words.contains(&word))
        .count();
    let french_score = common_french
        .iter()
        .filter(|&&word| words.contains(&word))
        .count();

    if english_score >= spanish_score && english_score >= french_score && english_score > 0 {
        Some("en".to_string())
    } else if spanish_score > french_score && spanish_score > 0 {
        Some("es".to_string())
    } else if french_score > 0 {
        Some("fr".to_string())
    } else {
        None
    }
}

/// Extract basic title from HTML
fn extract_title(html: &str) -> Option<String> {
    if let Some(start) = html.find("<title>") {
        if let Some(end) = html[start..].find("</title>") {
            let title = &html[start + 7..start + end];
            return Some(title.trim().to_string());
        }
    }
    None
}

/// Extract content based on mode
fn extract_content(html: &str, mode: &ExtractionMode) -> String {
    match mode {
        ExtractionMode::Article => extract_article_content(html),
        ExtractionMode::Full => html.to_string(),
        ExtractionMode::Metadata => extract_metadata_only(html),
        ExtractionMode::Custom(selectors) => extract_custom_content(html, selectors),
    }
}

/// Extract article content using simple heuristics
fn extract_article_content(html: &str) -> String {
    let content_tags = [
        "<article",
        "<main",
        "<div class=\"content",
        "<div id=\"content",
        "<div class=\"post",
        "<div class=\"entry",
    ];

    for tag in &content_tags {
        if let Some(start) = html.find(tag) {
            let tag_name = tag
                .trim_start_matches('<')
                .split(' ')
                .next()
                .unwrap_or("div");
            let closing_tag = format!("</{}>", tag_name);

            if let Some(end) = html[start..].find(&closing_tag) {
                return html[start..start + end + closing_tag.len()].to_string();
            }
        }
    }

    // Fallback: extract body content
    if let Some(start) = html.find("<body") {
        if let Some(body_start) = html[start..].find('>') {
            let body_start = start + body_start + 1;
            if let Some(end) = html[body_start..].find("</body>") {
                return html[body_start..body_start + end].to_string();
            }
        }
    }

    html.to_string()
}

/// Extract only metadata
fn extract_metadata_only(html: &str) -> String {
    let mut metadata = String::new();

    // Extract title
    if let Some(title) = extract_title(html) {
        metadata.push_str(&format!("Title: {}\n", title));
    }

    // Extract meta description
    if let Some(description) = extract_description(html) {
        metadata.push_str(&format!("Description: {}\n", description));
    }

    metadata
}

/// Extract content using custom selectors (simplified)
fn extract_custom_content(html: &str, selectors: &[String]) -> String {
    // Simplified implementation - just search for class/id patterns
    for selector in selectors {
        let search_pattern = if selector.starts_with('.') {
            format!("class=\"{}\"", &selector[1..])
        } else if selector.starts_with('#') {
            format!("id=\"{}\"", &selector[1..])
        } else {
            format!("<{}", selector)
        };

        if let Some(start) = html.find(&search_pattern) {
            // Find the containing element
            let tag_start = html[..start].rfind('<').unwrap_or(start);
            if let Some(tag_end) = html[tag_start..].find('>') {
                let tag = &html[tag_start + 1..tag_start + tag_end];
                let tag_name = tag.split(' ').next().unwrap_or("div");
                let closing_tag = format!("</{}>", tag_name);

                if let Some(end) = html[start..].find(&closing_tag) {
                    return html[tag_start..start + end + closing_tag.len()].to_string();
                }
            }
        }
    }

    extract_article_content(html)
}

/// Strip HTML tags from content
fn strip_html_tags(html: &str) -> String {
    let mut result = String::new();
    let mut in_tag = false;
    let mut in_script = false;
    let mut in_style = false;

    let mut chars = html.chars().peekable();
    while let Some(ch) = chars.next() {
        match ch {
            '<' => {
                in_tag = true;
                // Check for script/style tags
                let upcoming: String = chars.clone().take(10).collect();
                if upcoming.to_lowercase().starts_with("script") {
                    in_script = true;
                } else if upcoming.to_lowercase().starts_with("style") {
                    in_style = true;
                } else if upcoming.to_lowercase().starts_with("/script") {
                    in_script = false;
                } else if upcoming.to_lowercase().starts_with("/style") {
                    in_style = false;
                }
            }
            '>' => {
                in_tag = false;
            }
            _ if !in_tag && !in_script && !in_style => {
                result.push(ch);
            }
            _ => {}
        }
    }

    // Clean up whitespace
    result.split_whitespace().collect::<Vec<_>>().join(" ")
}

/// Extract links from HTML
fn extract_links(html: &str) -> Vec<String> {
    let mut links = Vec::new();
    let mut pos = 0;

    while let Some(start) = html[pos..].find("href=\"") {
        let start = pos + start + 6;
        if let Some(end) = html[start..].find('"') {
            let link = &html[start..start + end];
            if link.starts_with("http") {
                links.push(link.to_string());
            }
        }
        pos = start;
    }

    links
}

/// Extract images from HTML
fn extract_images(html: &str) -> Vec<String> {
    let mut images = Vec::new();
    let mut pos = 0;

    while let Some(start) = html[pos..].find("src=\"") {
        let start = pos + start + 5;
        if let Some(end) = html[start..].find('"') {
            let src = &html[start..start + end];
            if src.starts_with("http") || src.starts_with("//") {
                let full_url = if src.starts_with("//") {
                    format!("https:{}", src)
                } else {
                    src.to_string()
                };
                images.push(full_url);
            }
        }
        pos = start;
    }

    images
}

/// Extract byline/author information
fn extract_byline(html: &str) -> Option<String> {
    let patterns = [
        "<meta name=\"author\" content=\"",
        "<span class=\"author\">",
        "<div class=\"byline\">",
        "<p class=\"author\">",
    ];

    for pattern in &patterns {
        if let Some(start) = html.find(pattern) {
            let content_start = start + pattern.len();
            let end_char = if pattern.contains("content=\"") {
                '"'
            } else {
                '<'
            };

            if let Some(end) = html[content_start..].find(end_char) {
                let author = html[content_start..content_start + end].trim();
                if !author.is_empty() {
                    return Some(author.to_string());
                }
            }
        }
    }

    None
}

/// Extract published date
fn extract_published_date(html: &str) -> Option<String> {
    let patterns = [
        "<meta property=\"article:published_time\" content=\"",
        "<meta name=\"date\" content=\"",
        "<time datetime=\"",
    ];

    for pattern in &patterns {
        if let Some(start) = html.find(pattern) {
            let content_start = start + pattern.len();
            if let Some(end) = html[content_start..].find('"') {
                let date = html[content_start..content_start + end].trim();
                if !date.is_empty() {
                    return Some(date.to_string());
                }
            }
        }
    }

    None
}

/// Extract site name
fn extract_site_name(html: &str) -> Option<String> {
    let patterns = [
        "<meta property=\"og:site_name\" content=\"",
        "<meta name=\"application-name\" content=\"",
    ];

    for pattern in &patterns {
        if let Some(start) = html.find(pattern) {
            let content_start = start + pattern.len();
            if let Some(end) = html[content_start..].find('"') {
                let site_name = html[content_start..content_start + end].trim();
                if !site_name.is_empty() {
                    return Some(site_name.to_string());
                }
            }
        }
    }

    None
}

/// Extract meta description
fn extract_description(html: &str) -> Option<String> {
    let patterns = [
        "<meta name=\"description\" content=\"",
        "<meta property=\"og:description\" content=\"",
    ];

    for pattern in &patterns {
        if let Some(start) = html.find(pattern) {
            let content_start = start + pattern.len();
            if let Some(end) = html[content_start..].find('"') {
                let description = html[content_start..content_start + end].trim();
                if !description.is_empty() {
                    return Some(description.to_string());
                }
            }
        }
    }

    None
}

/// Convert HTML content to markdown (simplified)
fn convert_to_markdown(html: &str) -> String {
    let mut markdown = html.to_string();

    // Replace headers
    markdown = markdown.replace("<h1>", "# ").replace("</h1>", "\n\n");
    markdown = markdown.replace("<h2>", "## ").replace("</h2>", "\n\n");
    markdown = markdown.replace("<h3>", "### ").replace("</h3>", "\n\n");

    // Replace paragraphs
    markdown = markdown.replace("<p>", "").replace("</p>", "\n\n");

    // Replace line breaks
    markdown = markdown.replace("<br>", "\n").replace("<br/>", "\n");

    // Replace emphasis
    markdown = markdown
        .replace("<strong>", "**")
        .replace("</strong>", "**");
    markdown = markdown.replace("<em>", "*").replace("</em>", "*");

    // Strip remaining HTML tags
    strip_html_tags(&markdown)
}

/// Extract content categories (fallback implementation)
fn extract_categories_fallback(title: &Option<String>, text: &str) -> Vec<String> {
    let mut categories = Vec::new();

    // Check title for category keywords
    if let Some(title) = title {
        let title_lower = title.to_lowercase();
        if title_lower.contains("news") || title_lower.contains("article") {
            categories.push("news".to_string());
        }
        if title_lower.contains("tech") || title_lower.contains("technology") {
            categories.push("technology".to_string());
        }
        if title_lower.contains("sport") || title_lower.contains("game") {
            categories.push("sports".to_string());
        }
        if title_lower.contains("business") || title_lower.contains("finance") {
            categories.push("business".to_string());
        }
        if title_lower.contains("health") || title_lower.contains("medical") {
            categories.push("health".to_string());
        }
    }

    // Check content for category keywords
    let text_lower = text.to_lowercase();
    if text_lower.contains("programming") || text_lower.contains("software") {
        categories.push("programming".to_string());
    }
    if text_lower.contains("politics") || text_lower.contains("government") {
        categories.push("politics".to_string());
    }

    if categories.is_empty() {
        categories.push("general".to_string());
    }

    categories
}

/// Calculate content quality score (fallback implementation)
fn calculate_quality_score_fallback(
    title: &Option<String>,
    text: &str,
    word_count: u32,
) -> Option<u8> {
    let mut score = 50u8; // Base score

    // Increase score based on content quality indicators
    if title.is_some() {
        score = score.saturating_add(10);
    }

    if word_count > 100 {
        score = score.saturating_add(10);
    }
    if word_count > 500 {
        score = score.saturating_add(10);
    }
    if word_count > 1000 {
        score = score.saturating_add(10);
    }

    // Check for structured content
    if text.contains("paragraph") || text.contains("section") {
        score = score.saturating_add(5);
    }

    Some(score.min(100))
}
