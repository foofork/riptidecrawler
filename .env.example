# ============================================================================
# RipTide API Configuration
# ============================================================================

# API endpoint URL (for CLI usage)
RIPTIDE_API_URL=http://localhost:8080

# API authentication key
RIPTIDE_API_KEY=your_api_key_here

# ============================================================================
# Core Services
# ============================================================================

# Redis connection URL
REDIS_URL=redis://localhost:6379/0

# Headless browser service URL
HEADLESS_URL=http://localhost:9123

# ============================================================================
# Search Configuration
# ============================================================================

# Search backend: "serper" (default), "none", or "searxng"
SEARCH_BACKEND=serper

# Serper.dev API key (required when SEARCH_BACKEND=serper)
SERPER_API_KEY=your_serper_api_key_here

# SearXNG instance URL (required when SEARCH_BACKEND=searxng)
# SEARXNG_BASE_URL=http://localhost:8888

# Search operation timeout in seconds
SEARCH_TIMEOUT=30

# Enable URL parsing for None provider
SEARCH_ENABLE_URL_PARSING=true

# ============================================================================
# Performance & Resource Limits
# ============================================================================

# Maximum concurrent render operations
RIPTIDE_MAX_CONCURRENT_RENDERS=10

# Maximum concurrent PDF operations (semaphore limit)
RIPTIDE_MAX_CONCURRENT_PDF=2

# Render timeout in seconds (hard cap: 3s recommended)
RIPTIDE_RENDER_TIMEOUT=3

# Rate limit: requests per second per host
RIPTIDE_RATE_LIMIT_RPS=1.5

# Rate limit jitter factor (0.0-1.0)
RIPTIDE_RATE_LIMIT_JITTER=0.1

# Browser pool size (max instances: 3 recommended)
RIPTIDE_HEADLESS_POOL_SIZE=3

# Global memory limit in MB
RIPTIDE_MEMORY_LIMIT_MB=2048

# ============================================================================
# LLM/AI Provider Configuration
# ============================================================================

# OpenAI Configuration
# OPENAI_API_KEY=sk-...
# OPENAI_BASE_URL=https://api.openai.com/v1

# Anthropic/Claude Configuration
# ANTHROPIC_API_KEY=sk-ant-...

# Azure OpenAI Configuration
# AZURE_OPENAI_KEY=your_azure_key
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com

# Ollama Configuration (local LLM)
# OLLAMA_BASE_URL=http://localhost:11434

# ============================================================================
# Telemetry & Observability
# ============================================================================

# Enable telemetry collection
TELEMETRY_ENABLED=true

# Service name for telemetry
TELEMETRY_SERVICE_NAME=riptide-api

# Service version (defaults to CARGO_PKG_VERSION)
# TELEMETRY_SERVICE_VERSION=1.0.0

# OpenTelemetry OTLP endpoint
# TELEMETRY_OTLP_ENDPOINT=http://localhost:4317

# Alternative OTEL endpoint
# OTEL_ENDPOINT=http://localhost:4317

# Telemetry exporter type: "otlp" or "stdout"
TELEMETRY_EXPORTER_TYPE=stdout

# Sampling ratio (0.0-1.0)
TELEMETRY_SAMPLING_RATIO=1.0

# Export timeout in seconds
TELEMETRY_EXPORT_TIMEOUT_SECS=30

# Maximum queue size
TELEMETRY_MAX_QUEUE_SIZE=2048

# Maximum export batch size
TELEMETRY_MAX_EXPORT_BATCH_SIZE=512

# ============================================================================
# Authentication & Security
# ============================================================================

# Comma-separated valid API keys
# API_KEYS=key1,key2,key3

# Require authentication (true/false)
REQUIRE_AUTH=false

# ============================================================================
# Advanced Features
# ============================================================================

# WASM extractor module path
# WASM_EXTRACTOR_PATH=./target/wasm32-wasi/release/extractor.wasm

# Enable spider/crawler functionality (set to true to enable deep crawling)
SPIDER_ENABLE=false

# Spider configuration (when enabled)
# Base URL for spider operations (required when SPIDER_ENABLE=true)
# SPIDER_BASE_URL=https://example.com

# Maximum crawl depth (default: 10)
SPIDER_MAX_DEPTH=3

# Maximum pages to crawl (default: 1000)
SPIDER_MAX_PAGES=100

# Concurrent requests (default: 4)
SPIDER_CONCURRENCY=4

# Request timeout in seconds (default: 30)
SPIDER_TIMEOUT_SECONDS=30

# Delay between requests in milliseconds (default: 500)
SPIDER_DELAY_MS=500

# Respect robots.txt (default: true)
SPIDER_RESPECT_ROBOTS=true

# User agent string (default: "RipTide Spider/1.0")
# SPIDER_USER_AGENT=RipTide Spider/1.0

# Enable enhanced processing pipeline
ENHANCED_PIPELINE_ENABLE=true

# Enhanced pipeline metrics
ENHANCED_PIPELINE_METRICS=true

# Enhanced pipeline debug logging
# ENHANCED_PIPELINE_DEBUG=true

# Pipeline timeouts (seconds)
# ENHANCED_PIPELINE_FETCH_TIMEOUT=10
# ENHANCED_PIPELINE_GATE_TIMEOUT=5
# ENHANCED_PIPELINE_WASM_TIMEOUT=5
# ENHANCED_PIPELINE_RENDER_TIMEOUT=3

# ============================================================================
# Worker Configuration
# ============================================================================

# Worker pool size
WORKER_POOL_SIZE=4

# Maximum batch size for worker operations
# WORKER_MAX_BATCH_SIZE=100

# Maximum concurrency for workers
# WORKER_MAX_CONCURRENCY=10

# Enable worker scheduler
# WORKER_ENABLE_SCHEDULER=true

# ============================================================================
# Cache & Persistence
# ============================================================================

# Cache TTL in seconds
CACHE_TTL=86400

# Cache default TTL in seconds
CACHE_DEFAULT_TTL_SECONDS=86400

# Enable compression for cache
ENABLE_COMPRESSION=true

# Enable multi-tenancy
ENABLE_MULTI_TENANCY=false

# ============================================================================
# Circuit Breaker Configuration
# ============================================================================

# Circuit breaker failure threshold (percentage 0-100)
CIRCUIT_BREAKER_FAILURE_THRESHOLD=50

# Circuit breaker timeout in milliseconds
CIRCUIT_BREAKER_TIMEOUT_MS=5000

# Circuit breaker minimum requests before opening
CIRCUIT_BREAKER_MIN_REQUESTS=5

# Circuit breaker recovery timeout in seconds
CIRCUIT_BREAKER_RECOVERY_TIMEOUT=60

# ============================================================================
# Streaming Configuration
# ============================================================================

# Stream buffer size
STREAM_BUFFER_SIZE=8192

# Maximum stream buffer size
STREAM_BUFFER_MAX_SIZE=65536

# WebSocket maximum message size
WS_MAX_MESSAGE_SIZE=16777216

# WebSocket ping interval in seconds
WS_PING_INTERVAL=30

# Maximum concurrent streams
STREAM_MAX_CONCURRENT=100

# Default stream timeout in seconds
STREAM_DEFAULT_TIMEOUT=300

# Enable stream rate limiting
STREAM_RATE_LIMIT_ENABLED=true

# Stream rate limit (requests per second)
STREAM_RATE_LIMIT_RPS=10

# ============================================================================
# Development & Testing
# ============================================================================

# Logging level (error, warn, info, debug, trace)
RUST_LOG=info

# Health check port (optional, defaults to main API port)
# HEALTH_CHECK_PORT=8081

# Git SHA for versioning (auto-populated in CI/CD)
# GIT_SHA=abc123

# Build timestamp (auto-populated in CI/CD)
# BUILD_TIMESTAMP=2024-01-01T00:00:00Z

# Test environment configuration
# TEST_REDIS_URL=redis://localhost:6379/15
# TEST_WASM_PATH=./test-wasm/extractor.wasm
# SKIP_PERSISTENCE_TESTS=true
# SKIP_REDIS_TESTS=true

# Test timeout multiplier
# TEST_TIMEOUT_MULTIPLIER=2.0

# Feature flags for testing
# RIPTIDE_FEATURE_PDF=true
# RIPTIDE_FEATURE_BENCHMARKS=true
# RIPTIDE_FEATURE_API_INTEGRATION=true

# ============================================================================
# Proxy Configuration
# ============================================================================

# HTTP/HTTPS proxy settings
# HTTP_PROXY=http://proxy.example.com:8080
# HTTPS_PROXY=http://proxy.example.com:8080