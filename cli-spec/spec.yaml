# RipTide CLI Specification v1.0
# Single source of truth for CLI behavior, commands, flags, and API mappings
#
# This spec drives the thin HTTP client architecture described in:
# - /docs/CLI-REFACTORING-PLAN.md
# - /docs/CLI-EXTRACTION-STRATEGY-ANALYSIS.md

version: "1.0.0"
name: "riptide"
about: "High-performance web crawler and content extraction CLI"

# Configuration precedence: flags > env > config_file
config:
  precedence: ["flags", "env", "config_file"]
  config_path: "~/.config/riptide/config.yaml"
  base_url:
    default: "http://localhost:8080"
    env: "RIPTIDE_BASE_URL"
    flag: "--url"

# Global flags available to all commands
global_flags:
  - name: url
    long: --url
    short: u
    env: RIPTIDE_BASE_URL
    default: "http://localhost:8080"
    help: "RipTide API server URL"

  - name: api-key
    long: --api-key
    short: k
    env: RIPTIDE_API_KEY
    help: "API authentication key"

  - name: output
    long: --output
    short: o
    values: [json, table, text, ndjson]
    default: text
    help: "Output format (json, table, text, ndjson)"

  - name: quiet
    long: --quiet
    short: q
    type: bool
    default: "false"
    help: "Suppress progress output (stderr)"

  - name: verbose
    long: --verbose
    short: v
    type: bool
    default: "false"
    help: "Verbose output with debug information"

# Exit codes used by CLI
exit_codes:
  success: 0           # Successful operation
  user_error: 1        # User/config/network error (4xx, connection issues)
  server_error: 2      # Server error (5xx, protocol errors)
  invalid_args: 3      # CLI argument validation failure

# HTTP status code to exit code mapping
error_mapping:
  # 4xx client errors -> exit code 1 (user error)
  "400": 1  # Bad Request
  "401": 1  # Unauthorized
  "403": 1  # Forbidden
  "404": 1  # Not Found
  "429": 1  # Too Many Requests

  # 5xx server errors -> exit code 2 (server error)
  "500": 2  # Internal Server Error
  "502": 2  # Bad Gateway
  "503": 2  # Service Unavailable
  "504": 2  # Gateway Timeout

  # Network errors -> exit code 1 (user/network error)
  connection_refused: 1
  timeout: 1
  dns_failed: 1

# v1.0 Commands: 7 essential commands covering 100% of core workflows
commands:
  # ========================================================================
  # EXTRACT - Advanced extraction with full strategy control (PRIMARY)
  # ========================================================================
  - name: extract
    about: "Extract content with advanced strategy control (PRIMARY command)"
    api:
      method: POST
      path: /extract

    args:
      - name: url
        type: positional
        required: true
        help: "URL to extract content from"

    flags:
      - name: strategy
        long: --strategy
        values: [auto, css, wasm, llm, multi]
        default: multi
        help: "Extraction strategy (auto, css, wasm, llm, multi)"

      - name: selector
        long: --selector
        help: "CSS selector for targeted extraction (use with --strategy css)"

      - name: pattern
        long: --pattern
        help: "Regex pattern for content extraction"

      - name: quality-threshold
        long: --quality-threshold
        type: float
        default: "0.7"
        help: "Minimum quality threshold (0.0-1.0)"

      - name: timeout
        long: --timeout
        type: int
        default: "30000"
        help: "Timeout in milliseconds"

      - name: output-file
        long: --output-file
        short: f
        help: "Save results to file"

      - name: metadata
        long: --metadata
        type: bool
        default: "false"
        help: "Include extraction metadata in output"

    examples:
      - command: "riptide extract https://example.com"
        description: "Extract content with default multi-strategy"

      - command: "riptide extract https://example.com --strategy css --selector article"
        description: "Extract using CSS selector"

      - command: "riptide extract https://example.com --strategy llm --quality-threshold 0.9"
        description: "High-quality LLM-powered extraction"

  # ========================================================================
  # SPIDER - Deep crawling with frontier management (automatic extraction)
  # ========================================================================
  - name: spider
    about: "Deep crawl with spider engine and frontier management"
    api:
      method: POST
      path: /spider/crawl

    args:
      - name: url
        type: positional
        required: true
        help: "Starting URL for spider crawl"

    flags:
      - name: depth
        long: --depth
        short: d
        type: int
        default: "3"
        help: "Maximum crawl depth"

      - name: pages
        long: --pages
        short: p
        type: int
        default: "100"
        help: "Maximum pages to crawl"

      - name: concurrency
        long: --concurrency
        short: c
        type: int
        default: "5"
        help: "Concurrent requests"

      - name: timeout
        long: --timeout
        short: t
        type: int
        default: "30"
        help: "Request timeout (seconds)"

    examples:
      - command: "riptide spider https://docs.example.com"
        description: "Spider crawl with default depth and page limits"

      - command: "riptide spider https://docs.example.com --depth 5 --pages 500"
        description: "Deep crawl with custom limits"

  # ========================================================================
  # SEARCH - Web search with content extraction (automatic, with streaming)
  # ========================================================================
  - name: search
    about: "Deep search with content extraction and streaming support"
    api:
      method: POST
      path: /deepsearch
      streaming_variant: /deepsearch/stream

    args:
      - name: query
        type: positional
        required: true
        help: "Search query"

    flags:
      - name: limit
        long: --limit
        short: l
        type: int
        default: "10"
        help: "Maximum results to return"

      - name: stream
        long: --stream
        type: bool
        default: "false"
        help: "Stream results as NDJSON"

      - name: include-content
        long: --include-content
        type: bool
        default: "false"
        help: "Extract full content from results"

      - name: timeout
        long: --timeout
        short: t
        type: int
        default: "60"
        help: "Search timeout (seconds)"

    examples:
      - command: 'riptide search "web scraping"'
        description: "Search with default limit"

      - command: 'riptide search "web scraping" --limit 20 --stream'
        description: "Stream results with custom limit"

  # ========================================================================
  # RENDER - Headless browser rendering for JavaScript-heavy sites
  # ========================================================================
  - name: render
    about: "Render JavaScript-heavy pages with headless browser"
    api:
      method: POST
      path: /render

    args:
      - name: url
        type: positional
        required: true
        help: "URL to render"

    flags:
      - name: wait
        long: --wait
        type: int
        default: "3000"
        help: "Wait time for JavaScript (milliseconds)"

      - name: screenshot
        long: --screenshot
        help: "Save screenshot to file"

      - name: pdf
        long: --pdf
        help: "Save PDF to file"

      - name: full-page
        long: --full-page
        type: bool
        default: "false"
        help: "Capture full page (not just viewport)"

    examples:
      - command: "riptide render https://app.example.com"
        description: "Render dynamic page"

      - command: "riptide render https://app.example.com --screenshot page.png"
        description: "Render and capture screenshot"

  # ========================================================================
  # DOCTOR - System health diagnostics and troubleshooting
  # ========================================================================
  - name: doctor
    about: "System health diagnostics and troubleshooting"
    api:
      method: GET
      path: /healthz

    flags:
      - name: full
        long: --full
        type: bool
        default: "false"
        help: "Full diagnostic report (API, Redis, Chrome pool, DNS)"

    logic:
      # Special diagnostic checks with remediation guidance
      checks:
        - name: api_server
          endpoint: /healthz
          critical: true
          remediation: "Start API server: ./target/release/riptide-api"

        - name: redis
          endpoint: /healthz
          field: dependencies.redis.status
          critical: true
          remediation: "Start Redis: docker run -d -p 6379:6379 redis:7-alpine"

        - name: headless_pool
          endpoint: /healthz
          field: dependencies.headless_service.status
          critical: false
          remediation: "Start Chrome pool: docker-compose up chrome-service"

    examples:
      - command: "riptide doctor"
        description: "Quick health check"

      - command: "riptide doctor --full"
        description: "Comprehensive diagnostics with remediation"

  # ========================================================================
  # CONFIG - Configuration management (local file operations, critical gap fix)
  # ========================================================================
  - name: config
    about: "Configuration management (view, set, unset, reset)"
    # Note: config command operates on local files, no API endpoint

    flags:
      - name: get
        long: --get
        help: "Get configuration value"

      - name: set
        long: --set
        help: "Set configuration value (format: key=value)"

      - name: unset
        long: --unset
        help: "Unset configuration value"

      - name: list
        long: --list
        type: bool
        default: "false"
        help: "List all configuration values"

      - name: reset
        long: --reset
        type: bool
        default: "false"
        help: "Reset to default configuration"

    examples:
      - command: "riptide config --list"
        description: "List all configuration"

      - command: 'riptide config --set api.url=http://production:8080'
        description: "Set API server URL"

      - command: "riptide config --get api.url"
        description: "Get current API URL"

  # ========================================================================
  # SESSION - Session management for authenticated crawling (12 API endpoints)
  # ========================================================================
  - name: session
    about: "Session management for authenticated crawling"
    # Note: session has multiple API endpoints, managed via subcommands

    flags:
      - name: list
        long: --list
        type: bool
        default: "false"
        help: "List all sessions"

      - name: create
        long: --create
        help: "Create new session with name"

      - name: delete
        long: --delete
        help: "Delete session by ID"

      - name: cookies
        long: --cookies
        help: "Import cookies from file"

    examples:
      - command: "riptide session --list"
        description: "List all active sessions"

      - command: "riptide session --create auth-session"
        description: "Create new authenticated session"

      - command: "riptide session --delete abc123"
        description: "Delete session by ID"
