[package]
name = "riptide-spider"
version = "2.0.0"
edition.workspace = true
license.workspace = true
authors.workspace = true
description = "Spider/crawler engine for RipTide web scraping framework"
keywords = ["web", "crawler", "spider", "scraping"]
categories = ["web-programming"]

[dependencies]
# Shared types to avoid circular dependencies
riptide-types = { path = "../riptide-types" }
riptide-config = { path = "../riptide-config" }
riptide-fetch = { path = "../riptide-fetch" }

# Core dependencies
anyhow.workspace = true
async-trait.workspace = true
serde = { workspace = true, features = ["derive"] }
serde_json.workspace = true
thiserror.workspace = true
tokio = { workspace = true, features = ["macros", "rt-multi-thread", "sync", "time"] }
futures.workspace = true

# HTTP and URL handling
reqwest.workspace = true
url.workspace = true
http.workspace = true

# Spider-specific
robotstxt = "0.2"
regex.workspace = true
dashmap.workspace = true
uuid.workspace = true
chrono.workspace = true

# Metrics and monitoring
tracing.workspace = true
sysinfo.workspace = true
psutil.workspace = true

# System
libc = "0.2"

# Serialization
schemars = { version = "0.8", features = ["chrono"] }

# XML parsing for sitemaps
xml = "0.8"

# WASM for memory management
wasmtime.workspace = true
wasmtime-wasi.workspace = true

# Random for robots
rand.workspace = true

[dev-dependencies]
tokio-test = "0.4"
tempfile.workspace = true
criterion = { version = "0.5", features = ["html_reports"] }

[features]
default = []
benchmarks = []

[[bench]]
name = "query_aware_benchmark"
path = "benches/query_aware_benchmark.rs"
harness = false
required-features = ["benchmarks"]
